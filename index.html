<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="VeasyGuide is a tool for low-vision learners that uses motion detection to identify instructor actions and dynamically highlight and magnify them in presentation videos, reducing cognitive load and improving engagement.">
  <meta property="og:title" content="VeasyGuide: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos"/>
  <meta property="og:description" content="VeasyGuide uses motion detection to highlight instructor actions in presentation videos, helping low-vision learners with real-time feedback, personalization, and reduced cognitive load."/>
  <meta property="og:url" content="https://yourwebsite.com"/>
  <meta property="og:image" content="static/images/carousel1.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="VeasyGuide: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos">
  <meta name="twitter:description" content="VeasyGuide helps low-vision learners by highlighting instructor actions in presentation videos, improving accessibility and engagement."/>
  <meta name="twitter:image" content="static/images/carousel1.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Presentation Videos, E-learning, Online learning, Accessibility, Video Accessibility, Visual Accessibility, Low Vision, Motion Detection, Universal Design, Instructor Actions, Visual Guidance, Magnification, Personalization, Real-time Feedback, Cognitive Load, Engagement, Attentiveness, Spatial Context, Visual Search">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>VeasyGuide</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
                VeasyGuide: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tomfluff.github.io" target="_blank">Yotam Sechayk</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://faculty.runi.ac.il/arik/site/index.asp" target="_blank">Ariel Shamir</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://amypavel.com/" target="_blank">Amy Pavel</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www-ui.is.s.u-tokyo.ac.jp/~takeo/" target="_blank">Takeo Igarashi</a><sup>1</sup>
                  </span>
                </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>
                        The University of Tokyo, <sup>2</sup>
                        Reichman University, <sup>3</sup>
                        The University of California, Berkeley </span>
                    <span class="author-block">Conference name and year</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://dl.acm.org/doi/10.1145/3663547.3746372" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper (ACM)</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/tomfluff/VeasyGuide" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2507.21837" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Try it Link -->
              <span class="link-block ">
                <a href="https://veasyguide.github.io/demo/" target="_blank"
                class="external-link button is-normal is-rounded is-primary has-text-black">
                <span class="icon">
                  <i class="fas fa-play"></i>
                </span>
                <span class="has-text-black">Try it (interactive demo)</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image-->
 <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image is-max-desktop">
        <img src="static/images/interface.svg" alt='Illustration of the VeasyGuide player and its settings. From left to right. First, the player interface showing a video of a "Machine Learning" slide, where the phrase "incomplete information" is highlighted with a red rectangle, and standard video controls are visible below; with two additional buttons "Highlight personalization panel," and "Zoom personalization panel." Then, illustration of the z-key with the text "Toggle", atop a magnified view of the highlighted portion of the slide with the phrase "incomplete information" at the center. Finally, multiple personalization option panels.'>
      </figure>
      <h2 class="subtitle has-text-centered">
        VeasyGuide's interface includes: (a) a video player with highlighted areas (red rectangle and hand pointer), (a.1) zoom settings toggle, (a.2) highlight settings toggle, (b) a zoomed window (toggled with the Z key), and (c) zoom and highlight settings panels. While watching a video, VeasyGuide auto-highlights pointing, marking, and sketching activities. Users can zoom into highlighted portions with the Z key, adjust zoom with arrow keys, and customize highlight and zoom appearance in real time.
      </h2>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-16by9 is-max-desktop">
    <div class="hero-body">
      <video id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/video_figure.mp4"
        type="video/mp4">
        <track kind="subtitles" src="static/videos/video_figure.vtt" srclang="en" label="English" default>
      </video>
      <h2 class="subtitle has-text-centered">
        Video figure for VeasyGuide. VeasyGuide is an assistive tool that aids low vision learners to gain visual access to pointing, marking, and sketching actions in educational presentation videos. Our study reveals it is also beneficial for sighted learners, enhancing their focus and engagement with the content.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Instructors often rely on visual actions such as pointing, marking, and sketching to convey information in educational presentation videos. These subtle visual cues often lack verbal descriptions, forcing low-vision (LV) learners to search for visual indicators or rely solely on audio, which can lead to missed information and increased cognitive load. To address this challenge, we conducted a co-design study with three LV participants and developed <strong>VeasyGuide</strong>, a tool that uses motion detection to identify instructor actions and dynamically highlight and magnify them. VeasyGuide produces familiar visual highlights that convey spatial context and adapt to diverse learners and content through extensive personalization and real-time visual feedback. VeasyGuide reduces visual search effort by clarifying what to look for and where to look. In an evaluation with 8 LV participants, learners demonstrated a significant improvement in detecting instructor actions, with faster response times and significantly reduced cognitive load. A separate evaluation with 8 sighted participants showed that VeasyGuide also enhanced engagement and attentiveness, suggesting its potential as a universally beneficial tool.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/success+speed.png" alt="detection success and duration results for low-vision participants"/>
        <h2 class="subtitle has-text-centered">
          <strong>Left:</strong> Visual search success rates of LV participants (L1L8) in the localization task under baseline and VeasyGuide conditions. <strong>Right:</strong> Visual search times of LV participants (L1-L8) in the localization task under baseline and VeasyGuide conditions.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/load.jpg" alt="Task load and cognitive effort results for low-vision participants"/>
        <h2 class="subtitle has-text-centered">
          Results of subjective evaluation of LV participants comparing the baseline to VeasyGuide. Blue tones indicate positive evaluation and red tones indicate negative evaluation. We indicate statistical significance (ùëù < 0.05) using *.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/full.jpg" alt="Full low-vision user results for detection success and duration."/>
        <h2 class="subtitle has-text-centered">
         Detailed breakdown of results for success rates and detection speeds from the localization task for both LV and sighted participants in the baseline and VeasyGuide conditions. ‚ÄúTotal,‚Äù is the total number of activities for that condition.
       </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Using VeasyGuide</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/general_example.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Using VeasyGuide to follow a presentation video and zoom into instructor actions.
          </h2>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/personalization_example.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Personalizing VeasyGuide for individual visual needs.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@inproceedings{sechayk2025VeasyGuide,
author = {Sechayk, Yotam and Shamir, Ariel and Pavel, Amy and Igarashi, Takeo},
title = {VeasyGuide: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos},
year = {2025},
isbn = {9798400706769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663547.3746372},
doi = {10.1145/3663547.3746372},
abstract = {Instructors often rely on visual actions such as pointing, marking, and sketching to convey information in educational presentation videos. These subtle visual cues often lack verbal descriptions, forcing low-vision (LV) learners to search for visual indicators or rely solely on audio, which can lead to missed information and increased cognitive load. To address this challenge, we conducted a co-design study with three LV participants and developed VeasyGuide, a tool that uses motion detection to identify instructor actions and dynamically highlight and magnify them. VeasyGuide produces familiar visual highlights that convey spatial context and adapt to diverse learners and content through extensive personalization and real-time visual feedback. VeasyGuide reduces visual search effort by clarifying what to look for and where to look. In an evaluation with 8 LV participants, learners demonstrated a significant improvement in detecting instructor actions, with faster response times and significantly reduced cognitive load. A separate evaluation with 8 sighted participants showed that VeasyGuide also enhanced engagement and attentiveness, suggesting its potential as a universally beneficial tool.},
booktitle = {Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {55},
numpages = {18},
keywords = {Presentation Videos, E-learning, Online learning, Accessibility, Video Accessibility, Visual Accessibility, Low Vision, Motion Detection, Universal Design},
location = {
},
series = {ASSETS '25}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
